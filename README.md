# pandas-memory-optimization ğŸš€

## Why this project?
When datasets grow large, poor data type choices can silently kill performance.
This project focuses on **optimizing pandas DataFrame memory usage** without losing
any business meaning or analytical value.

The goal is simple:
â¡ï¸ Make the data **lighter, faster, and scalable** for real-world ML pipelines.

---

## Problem Statement
The original customer dataset uses default pandas data types:
- Categorical columns stored as `object`
- Numeric columns stored as 64-bit by default
- Ordinal features not explicitly modeled

At scale, these inefficiencies:
- Increase memory consumption
- Slow down model training
- Increase infrastructure costs

---
## ğŸ“‚ Project Structure

```
pandas-memory-optimization/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ customer_train.csv 
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ dataframe_memory_optimization.ipynb
â”‚
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ hr-image-small.png
â”‚
â””â”€â”€ README.md

```

---

## What I Did

### ğŸ”§ Data Type Optimization
| Data Type | Optimization |
|---------|-------------|
| Binary categories | Converted to `bool` |
| Integer columns | Downcasted to `int32` |
| Float columns | Downcasted to `float16` |
| Nominal categories | Converted to `category` |
| Ordinal categories | Converted to **ordered categories** |

No numerical encoding for ordinal features â€” ordering is preserved **semantically**, not artificially.

---

### ğŸ“Š Ordinal Features Handled Correctly
- Experience level  
- Company size  
- Education level  
- University enrollment  
- Years since last job change  

These are modeled using `CategoricalDtype(ordered=True)` instead of integers.

---

## Business Logic Applied
Filtered the dataset to focus on recruiter-relevant candidates:
- **10+ years of experience**
- **Company size â‰¥ 1,000 employees**

This aligns the data with enterprise recruiter requirements.

---

## Results
âœ… Significant reduction in DataFrame memory usage  
âœ… No loss of information  
âœ… Faster and more scalable preprocessing  

Memory comparison can be verified using:
```python
df.info(memory_usage="deep")
